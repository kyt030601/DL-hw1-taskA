{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5cc9108-58d4-4ec5-8e11-6195dce3d5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 訓練 DynamicConv(hidden_dim=64, out_channels=64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|█████████████████████████████████████████████████████████████████████| 1979/1979 [01:42<00:00, 19.38it/s]\n",
      "Epoch 2: 100%|█████████████████████████████████████████████████████████████████████| 1979/1979 [01:43<00:00, 19.17it/s]\n",
      "Epoch 3: 100%|█████████████████████████████████████████████████████████████████████| 1979/1979 [01:41<00:00, 19.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 多通道測試：\n",
      "[RGB] Accuracy: 8.22%\n",
      "[RG] Accuracy: 2.00%\n",
      "[R] Accuracy: 2.00%\n",
      "[G] Accuracy: 2.00%\n",
      "[B] Accuracy: 1.78%\n",
      " FLOPs: 0.18M, Params: 115.83K\n",
      "\n",
      " 訓練 DynamicConv(hidden_dim=128, out_channels=64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|█████████████████████████████████████████████████████████████████████| 1979/1979 [01:42<00:00, 19.24it/s]\n",
      "Epoch 2: 100%|█████████████████████████████████████████████████████████████████████| 1979/1979 [01:41<00:00, 19.44it/s]\n",
      "Epoch 3: 100%|█████████████████████████████████████████████████████████████████████| 1979/1979 [01:45<00:00, 18.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 多通道測試：\n",
      "[RGB] Accuracy: 8.00%\n",
      "[RG] Accuracy: 2.44%\n",
      "[R] Accuracy: 1.78%\n",
      "[G] Accuracy: 2.22%\n",
      "[B] Accuracy: 1.33%\n",
      " FLOPs: 0.29M, Params: 226.67K\n",
      "\n",
      " 訓練 DynamicConv(hidden_dim=128, out_channels=32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|█████████████████████████████████████████████████████████████████████| 1979/1979 [01:44<00:00, 19.01it/s]\n",
      "Epoch 2: 100%|█████████████████████████████████████████████████████████████████████| 1979/1979 [01:44<00:00, 18.99it/s]\n",
      "Epoch 3: 100%|█████████████████████████████████████████████████████████████████████| 1979/1979 [01:43<00:00, 19.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 多通道測試：\n",
      "[RGB] Accuracy: 5.33%\n",
      "[RG] Accuracy: 2.67%\n",
      "[R] Accuracy: 2.00%\n",
      "[G] Accuracy: 2.44%\n",
      "[B] Accuracy: 1.33%\n",
      " FLOPs: 0.15M, Params: 113.62K\n",
      "\n",
      " 訓練 DynamicConv(hidden_dim=128, out_channels=128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|█████████████████████████████████████████████████████████████████████| 1979/1979 [01:51<00:00, 17.77it/s]\n",
      "Epoch 2: 100%|█████████████████████████████████████████████████████████████████████| 1979/1979 [01:52<00:00, 17.58it/s]\n",
      "Epoch 3: 100%|█████████████████████████████████████████████████████████████████████| 1979/1979 [01:51<00:00, 17.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 多通道測試：\n",
      "[RGB] Accuracy: 7.78%\n",
      "[RG] Accuracy: 2.67%\n",
      "[R] Accuracy: 2.00%\n",
      "[G] Accuracy: 2.22%\n",
      "[B] Accuracy: 1.78%\n",
      " FLOPs: 0.58M, Params: 452.79K\n",
      "\n",
      " Baseline CNN 模型測試\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline Epoch 1: 100%|████████████████████████████████████████████████████████████| 1979/1979 [01:38<00:00, 20.14it/s]\n",
      "Baseline Epoch 2: 100%|████████████████████████████████████████████████████████████| 1979/1979 [01:35<00:00, 20.62it/s]\n",
      "Baseline Epoch 3: 100%|████████████████████████████████████████████████████████████| 1979/1979 [01:36<00:00, 20.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline RGB] Accuracy: 6.22%\n",
      "[Baseline] FLOPs: 1.84M, Params: 5.04K\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from thop import profile\n",
    "\n",
    "# Dataset 定義\n",
    "class MiniImageNetDataset(Dataset):\n",
    "    def __init__(self, txt_file, img_dir, transform=None, channel_mask='RGB'):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.channel_mask = channel_mask\n",
    "        self.samples = []\n",
    "        with open(txt_file, 'r') as f:\n",
    "            for line in f:\n",
    "                path, label = line.strip().split()\n",
    "                self.samples.append((path, int(label)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "        img = Image.open(os.path.join(self.img_dir, path)).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            channel_indices = {'R': 0, 'G': 1, 'B': 2}\n",
    "            selected = [channel_indices[c] for c in self.channel_mask]\n",
    "            img = img[selected, :, :]\n",
    "        return img, label\n",
    "\n",
    "# Dynamic 卷積模組\n",
    "class DynamicChannelConv(nn.Module):\n",
    "    def __init__(self, max_in_channels, out_channels, kernel_size=3, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.max_in_channels = max_in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        self.weight_gen = nn.Sequential(\n",
    "            nn.Linear(max_in_channels, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, out_channels * max_in_channels * kernel_size * kernel_size)\n",
    "        )\n",
    "        self.bias = nn.Parameter(torch.zeros(out_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.size()\n",
    "        device = x.device\n",
    "        channel_indicator = torch.zeros((B, self.max_in_channels), device=device)\n",
    "        channel_indicator[:, :C] = 1.0\n",
    "        weights = self.weight_gen(channel_indicator)\n",
    "        weights = weights.view(B, self.out_channels, self.max_in_channels, self.kernel_size, self.kernel_size)\n",
    "\n",
    "        out = []\n",
    "        for i in range(B):\n",
    "            weight_i = weights[i, :, :C, :, :]\n",
    "            out_i = F.conv2d(x[i:i+1], weight_i, bias=self.bias, padding=self.kernel_size // 2)\n",
    "            out.append(out_i)\n",
    "        return torch.cat(out, dim=0)\n",
    "\n",
    "# Accuracy 計算函數\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    maxk = max(topk)\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    correct = pred.eq(target.view(-1, 1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:, :k].sum().item()\n",
    "        res.append(100.0 * correct_k / target.size(0))\n",
    "    return res\n",
    "\n",
    "# 設定參數\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "batch_size = 32\n",
    "num_classes = 50\n",
    "image_dir = 'C:/Users/kyt/Desktop/images'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 模型建立（支援 dynamic hidden dim 測試）\n",
    "def build_dynamic_model(hidden_dim=128, out_channels=64):\n",
    "    return nn.Sequential(\n",
    "        DynamicChannelConv(max_in_channels=3, out_channels=out_channels, hidden_dim=hidden_dim),\n",
    "        nn.ReLU(),\n",
    "        nn.AdaptiveAvgPool2d(1),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(out_channels, num_classes)\n",
    "    ).to(device)\n",
    "\n",
    "# baseline 模型（固定 RGB）\n",
    "def build_baseline_model():\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.AdaptiveAvgPool2d(1),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(64, num_classes)\n",
    "    ).to(device)\n",
    "\n",
    "# 動態模型 ablation 實驗（hidden_dim, out_channels 組合）\n",
    "hyper_configs = [(64, 64), (128, 64), (128, 32), (128, 128)]\n",
    "for hidden_dim, out_ch in hyper_configs:\n",
    "    print(f\"\\n 訓練 DynamicConv(hidden_dim={hidden_dim}, out_channels={out_ch})\")\n",
    "    model = build_dynamic_model(hidden_dim=hidden_dim, out_channels=out_ch)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    train_set = MiniImageNetDataset('train.txt', image_dir, transform)\n",
    "    val_set = MiniImageNetDataset('val.txt', image_dir, transform)\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size)\n",
    "\n",
    "    for epoch in range(3):\n",
    "        model.train()\n",
    "        running_loss = 0.0 \n",
    "        for x, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "    print(\"\\n 多通道測試：\")\n",
    "    test_channel_masks = ['RGB', 'RG', 'R', 'G', 'B']\n",
    "    for mask in test_channel_masks:\n",
    "        test_set = MiniImageNetDataset('test.txt', image_dir, transform, channel_mask=mask)\n",
    "        test_loader = DataLoader(test_set, batch_size=batch_size)\n",
    "\n",
    "        model.eval()\n",
    "        total_acc = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                out = model(x)\n",
    "                acc = accuracy(out, y)[0]\n",
    "                total_acc += acc * y.size(0)\n",
    "                total += y.size(0)\n",
    "        print(f\"[{mask}] Accuracy: {total_acc / total:.2f}%\")\n",
    "\n",
    "\n",
    "    dummy_input = torch.randn(1, 3, 32, 32).to(device)\n",
    "    macs, params = profile(model, inputs=(dummy_input,), verbose=False)\n",
    "    print(f\" FLOPs: {macs/1e6:.2f}M, Params: {params/1e3:.2f}K\")\n",
    "\n",
    "\n",
    "print(\"\\n Baseline CNN 模型測試\")\n",
    "model = build_baseline_model()\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "for epoch in range(3):\n",
    "    model.train()\n",
    "    for x, y in tqdm(train_loader, desc=f\"Baseline Epoch {epoch+1}\"):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "test_set = MiniImageNetDataset('test.txt', image_dir, transform, channel_mask='RGB')\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size)\n",
    "model.eval()\n",
    "total_acc = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        out = model(x)\n",
    "        acc = accuracy(out, y)[0]\n",
    "        total_acc += acc * y.size(0)\n",
    "        total += y.size(0)\n",
    "print(f\"[Baseline RGB] Accuracy: {total_acc / total:.2f}%\")\n",
    "from thop import profile\n",
    "dummy_input = torch.randn(1, 3, 32, 32).to(device)\n",
    "macs, params = profile(model, inputs=(dummy_input,), verbose=False)\n",
    "print(f\"[Baseline] FLOPs: {macs/1e6:.2f}M, Params: {params/1e3:.2f}K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da27fd24-8602-44b7-83c2-d27166eb9dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
